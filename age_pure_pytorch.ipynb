{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.3 64-bit ('base': conda)",
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "metadata": {
    "interpreter": {
     "hash": "98b0a9b7b4eaaa670588a142fd0a9b87eaafe866f1db4228be72b4211d12040f"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import functools\n",
    "import random\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim import lr_scheduler, swa_utils\n",
    "import torchvision\n",
    "from torchvision.datasets import ImageFolder, DatasetFolder\n",
    "from torchvision import transforms\n",
    "from diskcache import Cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cache = Cache('.cache/diskcache')\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "PATH = 'data/face_age'\n",
    "\n",
    "\n",
    "@cache.memoize()\n",
    "def imgpath_to_normalized_tensor(imgpath):\n",
    "        # makes a tensor, scales range to 0-1 and normalizes to same as imagenet\n",
    "        normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                    std=[0.229, 0.224, 0.225])\n",
    "        img = normalize(transforms.PILToTensor()(Image.open(imgpath)).float()/255)\n",
    "        return img\n",
    "\n",
    "\n",
    "class Ageset(Dataset):\n",
    "    def __init__(self, path, transforms = None, valid=False, split_pct = 0.3):\n",
    "        self.image_paths = list(Path(path).rglob(\"*.png\"))\n",
    "        random.seed(42)\n",
    "        random.shuffle(self.image_paths)\n",
    "        split_point = int(len(self)*0.3)\n",
    "        if valid:\n",
    "            self.image_paths = self.image_paths[:split_point]\n",
    "            print('len validation dataset', len(self.image_paths))\n",
    "        else:\n",
    "            self.image_paths = self.image_paths[split_point:]\n",
    "            print('len train dataset', len(self.image_paths))\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    # @functools.lru_cache(maxsize=None)\n",
    "    @classmethod # somehow this is needed for diskcache to work properly. Or define the function outside of the class\n",
    "    @cache.memoize()\n",
    "    def imgpath_to_normalized_tensor(cls,imgpath):\n",
    "            # makes a tensor, scales range to 0-1 and normalizes to same as imagenet\n",
    "            normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                        std=[0.229, 0.224, 0.225])\n",
    "            img = normalize(transforms.PILToTensor()(Image.open(imgpath)).float()/255)\n",
    "            return img\n",
    "            \n",
    "    def __getitem__(self,i):\n",
    "        if isinstance(i, slice):\n",
    "            return [self[n] for n,_ in enumerate(self.image_paths[i])]\n",
    "        \n",
    "        return (self.imgpath_to_normalized_tensor(self.image_paths[i]),\n",
    "                int(self.image_paths[i].parent.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_tensor_dataset(path, max_len=None):\n",
    "    image_paths = list(Path(path).rglob(\"*.png\"))\n",
    "    random.shuffle(image_paths)\n",
    "    if max_len:\n",
    "        image_paths = image_paths[:max_len]\n",
    "    \n",
    "    xs = torch.empty(len(image_paths), 3,200,200)\n",
    "    print('empty created')\n",
    "    for i, loc in enumerate(image_paths):\n",
    "        if i%1000==0: print(i)\n",
    "        xs[i] = imgpath_to_normalized_tensor(loc)\n",
    "    torch.save(xs,'data/input/xs')\n",
    "\n",
    "    print('done')\n",
    "\n",
    "    ys = torch.stack([torch.Tensor([int(Path(loc).parent.name)]) for loc in image_paths])\n",
    "    torch.save(ys,'data/input/ys')\n",
    "    print('done')\n",
    "    return None\n",
    "construct_tensor_dataset(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(ys,'data/input/ys')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "8.742213249206543"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "19556*200*200*3*4/1024**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgeTensorDataset(TensorDataset):\n",
    "    def __init__(self, xs, ys, valid=False, split_pct=0.3):\n",
    "        length = len(xs)\n",
    "        split = int(xs.shape[0]*split_pct)\n",
    "        if valid:\n",
    "            super().__init__(xs[:split],ys[:split])\n",
    "        else:\n",
    "            super().__init__(xs[split:],ys[split:])\n",
    "\n",
    "    def __getitem__(self,x):\n",
    "        return super().__getitem__(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgeResnet(nn.Module):\n",
    "    def __init__(self, size='18', feat_extract=False):\n",
    "        super().__init__()\n",
    "        resnet = 'torchvision.models.resnet'+size+'(pretrained=True)'\n",
    "        resnet = eval(resnet)\n",
    "        modules=list(resnet.children())[:-1]\n",
    "        self.resnet =nn.Sequential(*modules)\n",
    "\n",
    "        if feat_extract:\n",
    "            # with feature extraction we only train the linear layer and keep the resnet parameters fixed \n",
    "            for m in self.modules():\n",
    "                m.requires_grad_(False)\n",
    "\n",
    "        self.fc = nn.Linear(in_features=512, out_features=1, bias=True)\n",
    "        nn.init.kaiming_normal_(self.fc.weight)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = self.resnet(x)\n",
    "        x = torch.flatten(out, 1)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_size(dataset):\n",
    "    num_items = len(dataset)\n",
    "    img_dimensions = list(dataset[0][0].shape)\n",
    "    bytes_per_fp32 = 4\n",
    "    bytes_per_gb = 1024**3\n",
    "    size_in_gb = num_items * int(np.product(img_dimensions)) * bytes_per_fp32 / bytes_per_gb\n",
    "    print('items in dataset', num_items, 'img_dimensions', img_dimensions, 'size of ds in memory in gb:', size_in_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    best_loss = 1000000000\n",
    "    not_improve_count = 0\n",
    "    loss = {'train':[], 'val':[]}\n",
    "\n",
    "    for epoch in range(NUM_EPOCH):\n",
    "        print(f'Starting epoch {epoch}')\n",
    "        start_time = time.time()\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            total_loss = 0\n",
    "            for data in dls[phase]:\n",
    "                x, y = data[0].to(DEVICE), data[1].to(DEVICE)\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    pred = model(x)\n",
    "                    loss = loss_fn(y, pred)\n",
    "                    total_loss += loss * len(y)\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        opt.step()\n",
    "                        opt.zero_grad()\n",
    "                        if SWA_ENABLED and epoch > SWA_START:\n",
    "                            swa_model.update_parameters(model)\n",
    "                            swa_sched.step()\n",
    "                        elif SCHED_ENABLED:\n",
    "                            sched.step(loss)\n",
    "                            writer.add_scalar('lr/scheduler', sched.get_last_lr()[0], epoch)\n",
    "                        writer.add_scalar('lr/optparamgroup0', opt.param_groups[0]['lr'], epoch)\n",
    "                writer.add_scalar('batchloss/'+phase, loss, epoch)\n",
    "            \n",
    "            writer.add_scalar('loss/'+phase, total_loss/len(dls[phase].dataset), epoch)\n",
    "    \n",
    "        if total_loss < best_loss:\n",
    "            best_loss = total_loss\n",
    "            not_improve_count = 0\n",
    "        else:\n",
    "            not_improve_count += 1\n",
    "            if not_improve_count > 4:\n",
    "                print('early stopping!')\n",
    "                break\n",
    "            \n",
    "        print(f\"loss after epoch {epoch} : {total_loss / len(dls['val'].dataset)}\")\n",
    "        writer.add_scalar('time', (time.time()-start_time)/60, epoch)\n",
    "\n",
    "\n",
    "    if SWA_ENABLED:\n",
    "        # swa_utils.update_bn(train_dl, swa_model)\n",
    "        total_loss_train = 0\n",
    "        total_loss_val = 0\n",
    "        with torch.no_grad():\n",
    "            for data in train_dl:\n",
    "                    x, y = data[0].to(DEVICE), data[1].to(DEVICE)\n",
    "                    total_loss_train += loss_fn(y, model(x)) * len(y)\n",
    "            writer.add_scalar('loss/train', total_loss_train/len(train_set), epoch+1)\n",
    "\n",
    "            for data in val_dl:\n",
    "                    x, y = data[0].to(DEVICE), data[1].to(DEVICE)\n",
    "                    total_loss_val += loss_fn(y, model(x)) * len(y)\n",
    "            writer.add_scalar('loss/val', total_loss_train/len(val_set), epoch+1)\n",
    "\n",
    "    writer.flush()\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "RuntimeError",
     "evalue": "[enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 9386880000 bytes. Error code 12 (Cannot allocate memory)",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-de763ff96edf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mSCHED_ENABLED\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstruct_tensor_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data/face_age'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mtrain_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAgeTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-d6844323ebbb>\u001b[0m in \u001b[0;36mconstruct_tensor_dataset\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mimage_paths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"*.png\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_paths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mAgeset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgpath_to_normalized_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mloc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimage_paths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mloc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimage_paths\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mxs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at CPUAllocator.cpp:64] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 9386880000 bytes. Error code 12 (Cannot allocate memory)"
     ]
    }
   ],
   "source": [
    "# adam works best with lr of 0.001 (tested 0.1 and 0.01)\n",
    "# adam without scheduler works best\n",
    "# first it took 6 minutes to load all the datasets. With lru cache it was immediate (6GB memory use). With disk cache it took about 1-2 minutes. Great result\n",
    "import adabound\n",
    "\n",
    "def mae_loss(y, pred):\n",
    "    return (torch.abs(y-pred.T)).mean()\n",
    "loss_fn = mae_loss\n",
    "\n",
    "NUM_EPOCH = 40\n",
    "SWA_START = 30\n",
    "LR = 0.001\n",
    "BATCH_SIZE = 64\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "SWA_ENABLED = False\n",
    "SCHED_ENABLED = False\n",
    "\n",
    "xs,ys = construct_tensor_dataset('data/face_age')\n",
    "\n",
    "train_set = AgeTensorDataset(xs,ys, valid=False)\n",
    "determine_size(train_set)\n",
    "# train_set = Ageset(\"data/face_age\")[:4000]\n",
    "train_dl = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "val_set = AgeTensorDataset(xs,ys, valid=True)\n",
    "determine_size(test_set) \n",
    "# val_set = Ageset(\"data/face_age\", valid=True)[:1000]\n",
    "val_dl = DataLoader(val_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "dls = {'train': train_dl, 'val': val_dl}\n",
    "\n",
    "feat={True:'feat_ext', False:'finetune'}\n",
    "opts = {0:'adam',1:'adabound'}\n",
    "\n",
    "for i in [True, False]:\n",
    "    for j in range(2):\n",
    "\n",
    "        writer = SummaryWriter(comment=f'{feat[i]} opt {opts[j]} epoch {NUM_EPOCH} SWA_START {SWA_START} LR BATCH_SIZE {LR}')\n",
    "        model = AgeResnet(size='18', feat_extract=i)\n",
    "        model.to(DEVICE)\n",
    "\n",
    "        if j ==0:\n",
    "            opt = torch.optim.Adam(model.parameters(), LR)\n",
    "        if j ==1:\n",
    "            opt = adabound.AdaBound(model.parameters(), lr=1e-3, final_lr=0.1)\n",
    "\n",
    "\n",
    "        if SCHED_ENABLED:\n",
    "            # if i ==0:\n",
    "            #     sched = torch.optim.lr_scheduler.ReduceLROnPlateau(opt)\n",
    "            #     sched.get_last_lr = lambda: [1]\n",
    "            # if i == 1:\n",
    "            #     sched = torch.optim.lr_scheduler.OneCycleLR(opt, LR, steps_per_epoch=len(train_dl), epochs=NUM_EPOCH)\n",
    "            # if i == 2:\n",
    "            sched = torch.optim.lr_scheduler.MultiplicativeLR(opt, lr_lambda=lambda x: 1)\n",
    "        if SWA_ENABLED:\n",
    "            swa_model = swa_utils.AveragedModel(model)\n",
    "            swa_sched = swa_utils.SWALR(opt, swa_lr = 0.0005)\n",
    "        train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in test_set[:10]:\n",
    "    preds = i[1],model(i[0][None].to(DEVICE)).item()\n",
    "    print(f'target {preds[0]}, predicted {preds[1]}')\n",
    "    loss = abs(preds[0]-preds[1])\n",
    "    # print('loss',loss)\n",
    "    running += loss\n",
    "print(running, running/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "'tensorboard.main' is not recognized as an internal or external command,\noperable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!tensorboard.main --logdir='runs' ip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-0.2206122080485026"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "(a-time.time())/60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#launch tensorboard\n",
    "python -m tensorboard.main --logdir=runs --host=0.0.0.0 --port=6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard dev upload --logdir runs \\\n",
    "--name \"My latest experiment\" \\ # optional\n",
    "--description \"Simple comparison of several hyperparameters\" # optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-42-fcd86dbf9b07>, line 6)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-42-fcd86dbf9b07>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    def train(self:)\u001b[0m\n\u001b[0m                   ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class Learner():\n",
    "    def __init__(self, dls, model, opt, metric, parameters, sched=None, swa_model=None, swa_sched=None):\n",
    "        self.dls, self.model, self.opt, self.metric, self.p = dls, model, opt, metric, parameters\n",
    "        self.sched, self.swa_model, self.swa_sched = sched, swa_model, swa_sched\n",
    "        \n",
    "    def train(self:)\n",
    "        for epoch in range(NUM_EPOCH):\n",
    "                print('epoch start')\n",
    "                self.model.train()\n",
    "                total_loss_train = 0\n",
    "                for data in self.train_dl:\n",
    "                    x, y = data[0].to(DEVICE), data[1].to(DEVICE)\n",
    "                    opt.zero_grad()\n",
    "                    pred = model(x)\n",
    "                    loss = loss_fn(y, pred)\n",
    "                    total_loss_train += loss * len(y)\n",
    "                    loss.backward()\n",
    "                    opt.step()\n",
    "                    if epoch > SWA_START:\n",
    "                        swa_model.update_parameters(model)\n",
    "                        swa_sched.step(loss)\n",
    "                    else:\n",
    "                        sched.step()\n",
    "                \n",
    "                model.eval()\n",
    "                total_loss_test = 0\n",
    "                with torch.no_grad():\n",
    "                    for data in test_dl:\n",
    "                        x, y = data[0].to(DEVICE), data[1].to(DEVICE)\n",
    "                        total_loss_test += loss_fn(y, model(x)) * len(y)\n",
    "                register_runs(total_loss_train, total_loss_test, epoch)\n",
    "\n",
    "    def register_runs(total_loss_train, total_loss_test, epoch): \n",
    "        writer.add_scalar('loss/train', total_loss_train/len(train_set), epoch)\n",
    "        writer.add_scalar('loss/test', total_loss_test/len(test_set), epoch)\n",
    "        writer.add_scalar('lr/optparamgroup0', opt.param_groups[0]['lr'], epoch)\n",
    "        writer.add_scalar('lr/scheduler', sched.get_last_lr()[0], epoch)\n",
    "        print(f'loss after epoch {epoch}: {total_loss_train/len(train_set)}, {total_loss_test/len(test_set)}')\n",
    "\n",
    "    def validate_swa_model(swa_model):\n",
    "        # swa_utils.update_bn(train_dl, swa_model)\n",
    "        total_loss_train = 0\n",
    "            total_loss_test = 0\n",
    "            with torch.no_grad():\n",
    "            for data in train_dl:\n",
    "                    x, y = data[0].to(DEVICE), data[1].to(DEVICE)\n",
    "                    total_loss_train += loss_fn(y, model(x)) * len(y)\n",
    "            writer.add_scalar('loss/train', total_loss_train/len(train_set), epoch+1)\n",
    "\n",
    "            for data in test_dl:\n",
    "                    x, y = data[0].to(DEVICE), data[1].to(DEVICE)\n",
    "                    total_loss_test += loss_fn(y, model(x)) * len(y)\n",
    "            writer.add_scalar('loss/test', total_loss_train/len(test_set), epoch+1)\n",
    "\n",
    "            writer.flush()\n",
    "            writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "8.742213249206543"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "9386880000/1024**3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(device(type='cpu'), device(type='cuda', index=0))"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "a = torch.Tensor([2])\n",
    "b = a.to(DEVICE)\n",
    "a.device, b.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}
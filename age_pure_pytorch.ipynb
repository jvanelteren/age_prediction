{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.7.3 64-bit",
   "display_name": "Python 3.7.3 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "ecf5722fdaf1897a315d257d89d94520bfcaa453217d5becf09b39e73618b0de"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "import torchvision\n",
    "from pathlib import Path\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim import lr_scheduler, swa_utils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ageset(Dataset):\n",
    "\n",
    "    def __init__(self, path, transforms = None, valid=False, split_pct = 0.3):\n",
    "        self.image_paths = list(Path(path).rglob(\"*.png\"))\n",
    "        random.seed(42)\n",
    "\n",
    "        random.shuffle(self.image_paths)\n",
    "        print(len(self.image_paths))\n",
    "        split_point = int(len(self)*0.3)\n",
    "        if valid:\n",
    "            self.image_paths = self.image_paths[:split_point]\n",
    "            print(len(self.image_paths))\n",
    "        else:\n",
    "            self.image_paths = self.image_paths[split_point:]\n",
    "            print(len(self.image_paths))\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def imgpath_to_tensor(self, imgpath):\n",
    "        return transforms.PILToTensor()(Image.open(imgpath)).float()\n",
    "\n",
    "    def __getitem__(self,i):\n",
    "        # return self.image_paths[i]\n",
    "        if isinstance(i, slice):\n",
    "            return [self[n] for n,_ in enumerate(self.image_paths[i])]\n",
    "        return (self.imgpath_to_tensor(self.image_paths[i]),\n",
    "                int(self.image_paths[i].parent.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class adaptedRes(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(adaptedRes, self).__init__()\n",
    "        resnet = torchvision.models.resnet18(pretrained=True)\n",
    "        modules=list(resnet.children())[:-1]\n",
    "        self.resnet =nn.Sequential(*modules)\n",
    "        self.fc = nn.Linear(in_features=512, out_features=1, bias=True)\n",
    "\n",
    "        # for m in self.modules():\n",
    "        # if isinstance(m, nn.Linear):\n",
    "        nn.init.kaiming_normal_(self.fc.weight)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = self.resnet(x)\n",
    "        x = torch.flatten(out, 1)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mae_loss(y, pred):\n",
    "    return (torch.abs(y-pred.T)).mean()\n",
    "loss_fn = mae_loss\n",
    "\n",
    "NUM_EPOCH = 7\n",
    "SWA_START = 3\n",
    "# LR = 0.0005\n",
    "BATCH_SIZE = 64\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "SWA_ENABLED = False\n",
    "SCHED_ENABLED = False\n",
    "\n",
    "train_set = Ageset(\"data/face_age\")[:64*50]\n",
    "train_dl = DataLoader(train_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "test_set = Ageset(\"data/face_age\", valid=True)[:64*10]\n",
    "test_dl = DataLoader(test_set, batch_size=BATCH_SIZE, shuffle=True)\n",
    "dls = {'train': train_dl, 'test': test_dl}\n",
    "\n",
    "for LR in [0.1,0.01,0.001]:\n",
    "    writer = SummaryWriter(comment=f'epoch {NUM_EPOCH} SWA_START {SWA_START} LR BATCH_SIZE {LR}')\n",
    "    model = adaptedRes()\n",
    "    model.to(DEVICE)\n",
    "    opt = torch.optim.Adam(model.parameters(), LR)\n",
    "\n",
    "    if SCHED_ENABLED:\n",
    "        sched = lr_scheduler.OneCycleLR(opt, max_lr=0.001,steps_per_epoch=len(train_dl), epochs=NUM_EPOCH)\n",
    "\n",
    "    if SWA_ENABLED:\n",
    "        swa_model = swa_utils.AveragedModel(model)\n",
    "        swa_sched = swa_utils.SWALR(opt, swa_lr = 0.0005)\n",
    "    # train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "\n",
    "    loss = {'train':[], 'test':[]}\n",
    "    for epoch in range(NUM_EPOCH):\n",
    "        print('epoch start')\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            total_loss = 0\n",
    "            for data in dls[phase]:\n",
    "                x, y = data[0].to(DEVICE), data[1].to(DEVICE)\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    pred = model(x)\n",
    "                    loss = loss_fn(y, pred)\n",
    "                    total_loss += loss * len(y)\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        opt.step()\n",
    "                        opt.zero_grad()\n",
    "                        if SWA_ENABLED and epoch > SWA_START:\n",
    "                            swa_model.update_parameters(model)\n",
    "                            swa_sched.step()\n",
    "                        elif SCHED_ENABLED:\n",
    "                            sched.step()\n",
    "                            writer.add_scalar('lr/scheduler', sched.get_last_lr()[0], epoch)\n",
    "                        writer.add_scalar('lr/optparamgroup0', opt.param_groups[0]['lr'], epoch)\n",
    "            \n",
    "                    writer.add_scalar('loss/'+phase', total_loss/len(train_set), epoch)\n",
    "            \n",
    "        print(f'loss after epoch {epoch}: {total_loss_train/len(train_set)}, {total_loss_test/len(test_set)}')\n",
    "\n",
    "    if SWA_ENABLED:\n",
    "        # swa_utils.update_bn(train_dl, swa_model)\n",
    "        total_loss_train = 0\n",
    "        total_loss_test = 0\n",
    "        with torch.no_grad():\n",
    "            for data in train_dl:\n",
    "                    x, y = data[0].to(DEVICE), data[1].to(DEVICE)\n",
    "                    total_loss_train += loss_fn(y, model(x)) * len(y)\n",
    "            writer.add_scalar('loss/train', total_loss_train/len(train_set), epoch+1)\n",
    "\n",
    "            for data in test_dl:\n",
    "                    x, y = data[0].to(DEVICE), data[1].to(DEVICE)\n",
    "                    total_loss_test += loss_fn(y, model(x)) * len(y)\n",
    "            writer.add_scalar('loss/test', total_loss_train/len(test_set), epoch+1)\n",
    "\n",
    "    writer.flush()\n",
    "    writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "target 16, predicted -0.47240400314331055\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'running' is not defined",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-63bee9934c35>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mpreds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;31m# print('loss',loss)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mrunning\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrunning\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'running' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in test_set[:10]:\n",
    "    preds = i[1],model(i[0][None].to(DEVICE)).item()\n",
    "    print(f'target {preds[0]}, predicted {preds[1]}')\n",
    "    loss = abs(preds[0]-preds[1])\n",
    "    # print('loss',loss)\n",
    "    running += loss\n",
    "print(running, running/2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "'tensorboard.main' is not recognized as an internal or external command,\noperable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!tensorboard.main --logdir='runs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.0005"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "opt.param_groups[0]['lr']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#launch tensorboard\n",
    "python -m tensorboard.main --logdir=path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard dev upload --logdir runs \\\n",
    "--name \"My latest experiment\" \\ # optional\n",
    "--description \"Simple comparison of several hyperparameters\" # optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner():\n",
    "    def __init__(self, dls, model, opt, metric, parameters, sched=None, swa_model=None, swa_sched=None):\n",
    "        self.dls, self.model, self.opt, self.metric, self.p = dls, model, opt, metric, parameters\n",
    "        self.sched, self.swa_model, self.swa_sched = sched, swa_model, swa_sched\n",
    "        \n",
    "    def train(self:)\n",
    "        for epoch in range(NUM_EPOCH):\n",
    "                print('epoch start')\n",
    "                self.model.train()\n",
    "                total_loss_train = 0\n",
    "                for data in self.train_dl:\n",
    "                    x, y = data[0].to(DEVICE), data[1].to(DEVICE)\n",
    "                    opt.zero_grad()\n",
    "                    pred = model(x)\n",
    "                    loss = loss_fn(y, pred)\n",
    "                    total_loss_train += loss * len(y)\n",
    "                    loss.backward()\n",
    "                    opt.step()\n",
    "                    if epoch > SWA_START:\n",
    "                        swa_model.update_parameters(model)\n",
    "                        swa_sched.step()\n",
    "                    else:\n",
    "                        sched.step()\n",
    "                \n",
    "                model.eval()\n",
    "                total_loss_test = 0\n",
    "                with torch.no_grad():\n",
    "                    for data in test_dl:\n",
    "                        x, y = data[0].to(DEVICE), data[1].to(DEVICE)\n",
    "                        total_loss_test += loss_fn(y, model(x)) * len(y)\n",
    "                register_runs(total_loss_train, total_loss_test, epoch)\n",
    "\n",
    "    def register_runs(total_loss_train, total_loss_test, epoch): \n",
    "        writer.add_scalar('loss/train', total_loss_train/len(train_set), epoch)\n",
    "        writer.add_scalar('loss/test', total_loss_test/len(test_set), epoch)\n",
    "        writer.add_scalar('lr/optparamgroup0', opt.param_groups[0]['lr'], epoch)\n",
    "        writer.add_scalar('lr/scheduler', sched.get_last_lr()[0], epoch)\n",
    "        print(f'loss after epoch {epoch}: {total_loss_train/len(train_set)}, {total_loss_test/len(test_set)}')\n",
    "\n",
    "    def validate_swa_model(swa_model):\n",
    "        # swa_utils.update_bn(train_dl, swa_model)\n",
    "        total_loss_train = 0\n",
    "            total_loss_test = 0\n",
    "            with torch.no_grad():\n",
    "            for data in train_dl:\n",
    "                    x, y = data[0].to(DEVICE), data[1].to(DEVICE)\n",
    "                    total_loss_train += loss_fn(y, model(x)) * len(y)\n",
    "            writer.add_scalar('loss/train', total_loss_train/len(train_set), epoch+1)\n",
    "\n",
    "            for data in test_dl:\n",
    "                    x, y = data[0].to(DEVICE), data[1].to(DEVICE)\n",
    "                    total_loss_test += loss_fn(y, model(x)) * len(y)\n",
    "            writer.add_scalar('loss/test', total_loss_train/len(test_set), epoch+1)\n",
    "\n",
    "            writer.flush()\n",
    "            writer.close()"
   ]
  }
 ]
}